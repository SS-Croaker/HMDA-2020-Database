{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ffiec.cfpb.gov/v2/data-browser-api/view/csv?states=AL,AK,AZ,AR,CA,CO,CT,DE,DC,FL,GA,HI,ID,IL,IN,IA,KS,KY,LA,ME,MD,MA,MI,MN,MS,MO,MT,NE,NV,NH,NJ,NM,NY,NC,ND,OH,OK,OR,PA,RI,SC,SD,TN,TX,UT,VT,VA,WA,WV,WI,WY,AS,GU,MP,PR,VI,UM,FM,MH,PW&years=2020\n"
     ]
    }
   ],
   "source": [
    "# HMDA Data Browser API\n",
    "# https://cfpb.github.io/hmda-platform/#data-browser-api\n",
    "\n",
    "# Import the libraries we need\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import random\n",
    "\n",
    "import requests\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "from requests.compat import urljoin\n",
    "#for creating a user based URL, 'urljoin' is used\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "import datetime\n",
    "from datetime import timezone, time\n",
    "from datetime import timedelta\n",
    "import time\n",
    "\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt  # To visualize\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "# Import seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "#api_url = \"https://ffiec.cfpb.gov/v2/data-browser-api/view/aggregations?states=MD&years=2018&actions_taken=5,6\"\n",
    "\n",
    "#csv_url = \"https://ffiec.cfpb.gov/v2/data-browser-api/view/csv?states=ND,SD,NE,KS,MN,IA,MO,WI,IL,IN,MI,OH&years=2019\"\n",
    "\n",
    "us_states = \"AL,AK,AZ,AR,CA,CO,CT,DE,DC,FL,GA,HI,ID,IL,IN,IA,KS,KY,LA,ME,MD,MA,MI,MN,MS,MO,MT,NE,NV,NH,NJ,NM,NY,NC,ND,OH,OK,OR,PA,RI,SC,SD,TN,TX,UT,VT,VA,WA,WV,WI,WY,AS,GU,MP,PR,VI,UM,FM,MH,PW\"\n",
    "#us_states = \"AL\"\n",
    "\n",
    "year = \"2020\"\n",
    "\n",
    "\n",
    "#us_states = \"AL,AK\"\n",
    "#csv_url = \"https://ffiec.cfpb.gov/v2/data-browser-api/view/csv?states=ND,SD,NE,KS,MN,IA,MO,WI,IL,IN,MI,OH&years=2019\"\n",
    "#us_states = \"AK,AL\"\n",
    "\n",
    "csv_url = \"https://ffiec.cfpb.gov/v2/data-browser-api/view/csv?states=%s&years=%s\"%(us_states,year)\n",
    "\n",
    "print(csv_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get JSON data from the API\n",
    "# https://stackoverflow.com/questions/36240495/bound-method-response-json-of-response-200/36240505\n",
    "\n",
    "\n",
    "#HMDA_Data = pd.read_csv(csv_url)\n",
    "\n",
    "#Dropping row after Loan Amount (from row 23 to 99)\n",
    "# https://www.geeksforgeeks.org/how-to-drop-one-or-multiple-columns-in-pandas-dataframe/\n",
    "# How to drop columns in panda\n",
    "#start = time.time()\n",
    "#read data in chunks of 10000 rows at a time\n",
    "#chunk = pd.read_csv(csv_url,chunksize=10000)\n",
    "\n",
    "#chunk.drop(chunk.iloc[:, 22:], inplace = True, axis = 1)\n",
    "\n",
    "#end = time.time()\n",
    "#print(\"Read csv with chunks: \",(end-start),\"sec\")\n",
    "#HMDA_Data = pd.concat(chunk)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#HMDA_Data.drop(HMDA_Data.iloc[:, 22:], inplace = True, axis = 1)\n",
    "\n",
    "#HMDA_Data.head()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read csv with chunks:  2592.1543254852295 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25361306"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the same CSV file 10X times faster and with 10X less memory\n",
    "#https://towardsdatascience.com/%EF%B8%8F-load-the-same-csv-file-10x-times-faster-and-with-10x-less-memory-%EF%B8%8F-e93b485086c7\n",
    "\n",
    "# Select only the required columns\n",
    "\n",
    "#req_cols = [\"activity_year\",\"lei\",\"state_code\",\"county_code\",\"conforming_loan_limit\",\"derived_loan_product_type\",\"derived_dwelling_category\",\"derived_ethnicity\",\"derived_race\",\"derived_sex\",\"action_taken\",\"purchaser_type\",\"preapproval\",\"loan_type\",\"loan_purpose\",\"lien_status\",\"reverse_mortgage\",\"open-end_line_of_credit\",\"business_or_commercial_purpose\",\"loan_amount\"]\n",
    "\n",
    "req_cols = [\"activity_year\",\"lei\",\"state_code\",\"derived_loan_product_type\",\"action_taken\",\"loan_type\",\"loan_purpose\",\"lien_status\",\"derived_race\",\"loan_amount\"]\n",
    "#req_cols = [\"activity_year\",\"lei\",\"state_code\",\"loan_amount\",\"action_taken\"]\n",
    "\n",
    "start = time.time()\n",
    "#read data in chunks of 10000 rows at a time\n",
    "chunk = pd.read_csv(csv_url,usecols=req_cols,chunksize=10000)\n",
    "\n",
    "#chunk.drop(chunk.iloc[:, 22:], inplace = True, axis = 1)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Read csv with chunks: \",(end-start),\"sec\")\n",
    "HMDA_Data = pd.concat(chunk)\n",
    "\n",
    "\n",
    "HMDA_Data = HMDA_Data.rename( columns= {'lei':'LEI'})\n",
    "\n",
    "len(HMDA_Data)\n",
    "#HMDA_Data.head()\n",
    "\n",
    "# https://www.kite.com/python/answers/how-to-get-a-pivot-table-with-counts-of-unique-column-values-from-a-pandas-dataframe-in-python\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   activity_year                   LEI state_code derived_loan_product_type  \\\n",
      "0           2020  254900AX110CHF6FVV28         NV   Conventional:First Lien   \n",
      "1           2020  254900AX110CHF6FVV28         TX            FHA:First Lien   \n",
      "2           2020  254900AX110CHF6FVV28         TX   Conventional:First Lien   \n",
      "3           2020  254900AX110CHF6FVV28         TX            FHA:First Lien   \n",
      "4           2020  254900AX110CHF6FVV28         TX            FHA:First Lien   \n",
      "\n",
      "                derived_race                        action_taken  \\\n",
      "0                      White  Application withdrawn by applicant   \n",
      "1                      White  Application withdrawn by applicant   \n",
      "2                      Asian                     Loan Originated   \n",
      "3                      White                     Loan Originated   \n",
      "4  Black or African American  Application withdrawn by applicant   \n",
      "\n",
      "      loan_type   loan_purpose              lien_status  loan_amount  \n",
      "0  Conventional  Home purchase  Secured by a first lien     195000.0  \n",
      "1           FHA  Home purchase  Secured by a first lien     145000.0  \n",
      "2  Conventional  Home purchase  Secured by a first lien     215000.0  \n",
      "3           FHA  Home purchase  Secured by a first lien     215000.0  \n",
      "4           FHA  Home purchase  Secured by a first lien     175000.0  \n"
     ]
    }
   ],
   "source": [
    "HMDA_Data['action_taken'] = HMDA_Data['action_taken'].astype(str)\n",
    "HMDA_Data['loan_type'] = HMDA_Data['loan_type'].astype(str)\n",
    "HMDA_Data['loan_purpose'] = HMDA_Data['loan_purpose'].astype(str)\n",
    "HMDA_Data['lien_status'] = HMDA_Data['lien_status'].astype(str)\n",
    "\n",
    "\n",
    "HMDA_Data['action_taken'] = HMDA_Data['action_taken'].replace({'1':'Loan Originated',\n",
    "                                                               '2':'Application approved but not accepted',\n",
    "                                                               '3': 'Application denied',\n",
    "                                                               '4':'Application withdrawn by applicant',\n",
    "                                                               '5':'File closed for incompleteness',\n",
    "                                                               '6':'Purchased loan',\n",
    "                                                               '7':'Preapproval request denied',\n",
    "                                                               '8':'Preapproval request approved but not accepted'})\n",
    "\n",
    "\n",
    "HMDA_Data['loan_type'] = HMDA_Data['loan_type'].replace({'1' : 'Conventional',\n",
    "                                                         '2' : 'FHA',\n",
    "                                                         '3' : 'VA',\n",
    "                                                         '4' : 'USDA'})\n",
    "\n",
    "\n",
    "HMDA_Data['loan_purpose'] = HMDA_Data['loan_purpose'].replace({'1' : 'Home purchase',\n",
    "                                                               '2' : 'Home improvement',\n",
    "                                                               '31' : 'Refinancing',\n",
    "                                                               '32' : 'Cash-out refinancing',\n",
    "                                                               '4' : 'Other purpose',\n",
    "                                                               '5' : 'Not applicable'})\n",
    "\n",
    "\n",
    "HMDA_Data['lien_status'] = HMDA_Data['lien_status'].replace({'1' : 'Secured by a first lien',\n",
    "                                                             '2' : 'Secured by a subordinate lien'})\n",
    "\n",
    "\n",
    "#HMDA_Data['construction_method'] = HMDA_Data['construction_method'].replace({'1' : 'Site-built',\n",
    "#                                                                             '2' : 'Manufactured home'})\n",
    "\n",
    "#HMDA_Data.head()\n",
    "print(HMDA_Data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HMDA_Data_pivot = pd.pivot_table(data = HMDA_Data, index = ['LEI'], columns=['activity_year'], aggfunc=len, fill_value=0)\n",
    "\n",
    "\n",
    "HMDA_Data_pivot_action_taken = pd.pivot_table(data = HMDA_Data, index = ['LEI'], columns = ['action_taken'],aggfunc={'state_code' : 'count', 'loan_amount' : 'sum'}, fill_value=0)\n",
    "HMDA_Data_pivot_action_taken = HMDA_Data_pivot_action_taken.rename( columns= {'state_code':'Total Number of Mortgages', 'loan_amount':'Total Loan Amount'})\n",
    "\n",
    "\n",
    "\n",
    "HMDA_Data_pivot_loan_type = pd.pivot_table(data = HMDA_Data, index = ['LEI'], columns = ['loan_type'],aggfunc={'state_code' : 'count', 'loan_amount' : 'sum'}, fill_value=0)\n",
    "HMDA_Data_pivot_loan_type = HMDA_Data_pivot_loan_type.rename( columns= {'state_code':'Total Number of Mortgages', 'loan_amount':'Total Loan Amount'})\n",
    "\n",
    "\n",
    "\n",
    "HMDA_Data_pivot_loan_purpose = pd.pivot_table(data = HMDA_Data, index = ['LEI'], columns = ['loan_purpose'],aggfunc={'state_code' : 'count', 'loan_amount' : 'sum'}, fill_value=0)\n",
    "HMDA_Data_pivot_loan_purpose = HMDA_Data_pivot_loan_purpose.rename( columns= {'state_code':'Total Number of Mortgages', 'loan_amount':'Total Loan Amount'})\n",
    "\n",
    "\n",
    "\n",
    "HMDA_Data_pivot_derived_race = pd.pivot_table(data = HMDA_Data, index = ['LEI'], columns = ['derived_race'],aggfunc={'state_code' : 'count', 'loan_amount' : 'sum'}, fill_value=0)\n",
    "HMDA_Data_pivot_derived_race = HMDA_Data_pivot_derived_race.rename( columns= {'state_code':'Total Number of Mortgages', 'loan_amount':'Total Loan Amount'})\n",
    "\n",
    "\n",
    "\n",
    "HMDA_Data_pivot_derived_loan_product_type = pd.pivot_table(data = HMDA_Data, index = ['LEI'], columns = ['derived_loan_product_type'],aggfunc={'state_code' : 'count', 'loan_amount' : 'sum'}, fill_value=0)\n",
    "HMDA_Data_pivot_derived_loan_product_type = HMDA_Data_pivot_derived_loan_product_type.rename( columns= {'state_code':'Total Number of Mortgages', 'loan_amount':'Total Loan Amount'})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Now we will convert the pivot table back to dataframe. For that we have to drop the empty column and then reset the index\n",
    "#Use 'rename_axis(None, axis=1)' with reset_index() to remove any categories you might have created while using pivot table\n",
    "\n",
    "#HMDA_Data_pivot.columns = HMDA_Data_pivot.columns.droplevel(0)\n",
    "#HMDA_Data_pivot = HMDA_Data_pivot.reset_index().rename_axis(None, axis=1) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#HMDA_Data_pivot.drop(HMDA_Data_pivot.iloc[:, 3:], inplace = True, axis = 1)\n",
    "\n",
    "\n",
    "#HMDA_Data_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91903\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\reshape\\merge.py:643: UserWarning: merging between different levels can give an unintended result (1 levels on the left,2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#Now we use vllookup to get LEI against HMDA count\n",
    "\n",
    "#https://www.geeksforgeeks.org/how-to-do-a-vlookup-in-python-using-pandas/\n",
    "\n",
    "lei_data_us = pd.read_csv(\"D:\\\\HMDA Data Analysis\\\\LEI Database USA.csv\")\n",
    "\n",
    "lei_data_us.head()\n",
    "\n",
    "HMDA_Count_action_taken = pd.merge(lei_data_us, HMDA_Data_pivot_action_taken, on ='LEI', how ='inner')\n",
    "HMDA_Count_action_taken.to_csv(\"D:\\\\HMDA Data Analysis\\\\HMDA Database %s\"%year+\"_All_By_Action_Taken.csv\")\n",
    "\n",
    "HMDA_Count_loan_type = pd.merge(lei_data_us, HMDA_Data_pivot_loan_type, on ='LEI', how ='inner')\n",
    "HMDA_Count_loan_type.to_csv(\"D:\\\\HMDA Data Analysis\\\\HMDA Database %s\"%year+\"_All_By_loan_type.csv\")\n",
    "\n",
    "HMDA_Count_loan_purpose = pd.merge(lei_data_us, HMDA_Data_pivot_loan_purpose, on ='LEI', how ='inner')\n",
    "HMDA_Count_loan_purpose.to_csv(\"D:\\\\HMDA Data Analysis\\\\HMDA Database %s\"%year+\"_All_By_loan_purpose.csv\")\n",
    "\n",
    "HMDA_Count_derived_race = pd.merge(lei_data_us, HMDA_Data_pivot_derived_race, on ='LEI', how ='inner')\n",
    "HMDA_Count_derived_race.to_csv(\"D:\\\\HMDA Data Analysis\\\\HMDA Database %s\"%year+\"_All_By_derived_race.csv\")\n",
    "\n",
    "HMDA_Count_derived_loan_product_type = pd.merge(lei_data_us, HMDA_Data_pivot_derived_loan_product_type, on ='LEI', how ='inner')\n",
    "HMDA_Count_derived_loan_product_type.to_csv(\"D:\\\\HMDA Data Analysis\\\\HMDA Database %s\"%year+\"_All_By__derived_loan_product_type.csv\")\n",
    "\n",
    "\n",
    "\n",
    "#HMDA_Count.head()\n",
    "#len(HMDA_Count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
